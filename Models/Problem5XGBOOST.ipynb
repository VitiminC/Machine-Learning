{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Charlie Lu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Charlie Lu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Charlie Lu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Charlie Lu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Charlie Lu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Charlie Lu\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Final Model = 0.8507110519086568\n",
      "Training Error = 0.1492889480913432\n",
      "Test Error = 0.14624408820097046\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier as xgbclass\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "table_header = [\"n_est\",\"max_depth\",\"lambda\",\"learning_rate\",\"missing\",\"objective\",\"accuracy\"]\n",
    "table_rows = []\n",
    "x_test, y_test = load_svmlight_file(\"a9a.t\")\n",
    "x_train, y_train = load_svmlight_file(\"a9a.txt\")\n",
    "\n",
    "\n",
    "'''\n",
    "#Checking default parameters\n",
    "default = xgbclass()\n",
    "default.fit(x_train, y_train)\n",
    "\n",
    "#predict on test with default\n",
    "prediction = default.predict(x_test)\n",
    "acc = accuracy_score(y_test, prediction)\n",
    "print(acc)\n",
    "print(default.get_params())\n",
    "'''\n",
    "\n",
    "'''\n",
    "#hyperparameter tuning - ***WARNING*** This will take a very long time ***WARNING***\n",
    "hyperparameters = []\n",
    "n_est = [150,200,250]\n",
    "max_depth = [2,3,4]\n",
    "lambda_r = [0.5,1,1.5,2]\n",
    "learning_rate = [0.15,0.2,0.25]\n",
    "missing = [np.nan,0]\n",
    "objective = ['binary:logistic','binary:hinge','binary:logitraw']\n",
    "best_acc = 0\n",
    "for a in n_est:\n",
    "    for b in max_depth:\n",
    "        for c in lambda_r:\n",
    "            for d in learning_rate:\n",
    "                for e in missing:\n",
    "                    for f in objective:\n",
    "                        new_model = xgbclass(n_estimators=a,\n",
    "                                             max_depth=b,\n",
    "                                             reg_lambda=c,\n",
    "                                             learning_rate=d,\n",
    "                                             missing=e,\n",
    "                                             objective=f,\n",
    "                                             eval_metric = 'logloss')\n",
    "                        \n",
    "                        cross_val = cross_val_score(new_model,x_train,y_train,cv=KFold())\n",
    "                        acc = cross_val.mean()\n",
    "                        table_rows.append([a,b,c,d,e,f,acc])\n",
    "                        if (best_acc < acc):\n",
    "                            best_acc = acc\n",
    "                            best_model = [a,b,c,d,e,f]\n",
    "                        \n",
    "\n",
    "print(best_acc)\n",
    "print(best_model)\n",
    "\n",
    "#Create CSV with all parameters and accuracies\n",
    "with open('Hyperparameters.csv', 'w') as f:\n",
    "    write = csv.writer(f,lineterminator = '\\n')   \n",
    "    write.writerow(table_header)\n",
    "    write.writerows(table_rows)\n",
    "'''\n",
    "\n",
    "#'''\n",
    "#best result was [200, 3, 1, 0.2, nan, 'binary:logistic']\n",
    "final_model = xgbclass(n_estimators=200,\n",
    "                       max_depth=3,\n",
    "                       reg_lambda=1,\n",
    "                       learning_rate=0.2,\n",
    "                       missing=np.nan,\n",
    "                       objective='binary:logistic',\n",
    "                       eval_metric = 'logloss')\n",
    "final_model.fit(x_train, y_train)\n",
    "cross_val = cross_val_score(final_model,x_train,y_train,cv=KFold())\n",
    "acc = cross_val.mean()\n",
    "print(\"Accuracy of Final Model = %s\" %acc)\n",
    "print(\"Training Error = %s\" %(1-cross_val.mean()))\n",
    "print(\"Test Error = %s\" %(1-final_model.score(x_test,y_test)))\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
